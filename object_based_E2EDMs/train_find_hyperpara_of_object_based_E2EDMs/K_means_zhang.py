# coding: UTF-8

import torch
import numpy as np
from utils import build_dataset, build_iterator
import csv
import datetime
from sklearn.cluster import KMeans
from scipy.cluster.vq import vq
import matplotlib.pyplot as plt
from config import Config
config = Config()



def cal_codebook(all_descriptors, num_clusters, position_info_range_in_all_info):


    start_flag = position_info_range_in_all_info[0]
    end_flag = position_info_range_in_all_info[1] + 1


    target_part_all_descriptors = all_descriptors[:, start_flag:end_flag]


    kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_jobs=-2)
    kmeans.fit(target_part_all_descriptors)


    return kmeans.cluster_centers_



def divide_all_object_info_to_each_kind(divide_num, all_object_info):

    kmeans_group = [list() for i in range(divide_num)]

    for j in all_object_info:
        for three_kinds in range(3):
            for i in j[three_kinds]:
                if three_kinds == 0: # moveable object
                    i = i[0]
                    previous_img_object_info = i[1]
                kmeans_group_serial_num = int(i[0]) - 1
                each_object_info = i[1:]
                kmeans_group[kmeans_group_serial_num].append(each_object_info)



    kmeans_group_numpy = []
    for each_kind_list in kmeans_group:
        each_kind_list_numpy = np.array(each_kind_list)
        kmeans_group_numpy.append(each_kind_list_numpy)

    return kmeans_group_numpy


def merge_2_kmeans_to_1_kmeans(feature_1, feature_2):
    feature_length_list = [len(feature_1), len(feature_2)]

    feature_1_cluster_serial_num = find_serial_num_infeature(feature_1)
    feature_2_cluster_serial_num = find_serial_num_infeature(feature_2)

    result_feature_length = feature_length_list[0] * feature_length_list[1]
    first_group_serial_num = feature_1_cluster_serial_num * feature_length_list[1]
    second_group_serial_num = feature_2_cluster_serial_num

    result_feature_serial_num = first_group_serial_num + second_group_serial_num
    result_feature = [0] * result_feature_length
    result_feature[result_feature_serial_num] = 1

    return result_feature


def merge_3_kmeans_to_1_kmeans(feature_1, feature_2, feature_3):
    feature_length_list = [len(feature_1), len(feature_2), len(feature_3)]

    feature_1_cluster_serial_num = find_serial_num_infeature(feature_1)
    feature_2_cluster_serial_num = find_serial_num_infeature(feature_2)
    feature_3_cluster_serial_num = find_serial_num_infeature(feature_3)

    result_feature_length = feature_length_list[0] * feature_length_list[1] * feature_length_list[2]
    first_group_serial_num = feature_1_cluster_serial_num * feature_length_list[1] * feature_length_list[2]
    second_group_serial_num = feature_2_cluster_serial_num * feature_length_list[2]
    third_group_serial_num = feature_3_cluster_serial_num
    result_feature_serial_num = first_group_serial_num + second_group_serial_num + third_group_serial_num
    result_feature = [0] * result_feature_length
    result_feature[result_feature_serial_num] = 1

    return result_feature


def find_serial_num_infeature(feature):
    for i in range(len(feature)):
        if feature[i] == 1:
            return i


def cal_moveableobject_feature(each_object_info, codebook):
    """
    Calculate the features of a single image given the codebook(vocabulary) generated by clustering method (kmeans), each column is the center of the cluster.
    :param img:
    :param codebook:
    :return:
    """
    object_position_info = each_object_info[0:2]
    object_size_info = each_object_info[2:4]
    object_motion_info = each_object_info[4:6]

    object_position_info_codebook = codebook[0]
    object_size_info_codebook = codebook[1]
    object_motion_info_codebook = codebook[2]

    position_info_features = np.zeros((object_position_info_codebook.shape[0]))
    size_info_features = np.zeros((object_size_info_codebook.shape[0]))
    motion_info_features = np.zeros((object_motion_info_codebook.shape[0]))

    # print(object_position_info, type(object_position_info)) # [600, 365]
    object_position_info = object_position_info[np.newaxis, :]
    object_size_info = object_size_info[np.newaxis, :]
    object_motion_info = object_motion_info[np.newaxis, :]

    code, _ = vq(object_position_info, object_position_info_codebook)
    position_info_features[code] += 1

    code, _ = vq(object_size_info, object_size_info_codebook)
    size_info_features[code] += 1

    code, _ = vq(object_motion_info, object_motion_info_codebook)
    motion_info_features[code] += 1

    result_feature = merge_3_kmeans_to_1_kmeans(position_info_features, size_info_features, motion_info_features)

    return result_feature


def cal_lane_object_feature(each_object_info, codebook):
    """
    Calculate the features of a single image given the codebook(vocabulary) generated by clustering method (kmeans), each column is the center of the cluster.
    :param img:
    :param codebook:
    :return:
    """
    object_start_point_info = each_object_info[0:2]
    object_end_point_info = each_object_info[2:4]

    object_start_point_info_codebook = codebook[0]
    object_end_point_info_codebook = codebook[1]

    object_start_point_info_features = np.zeros((object_start_point_info_codebook.shape[0]))
    object_end_point_info_features = np.zeros((object_end_point_info_codebook.shape[0]))

    object_start_point_info = object_start_point_info[np.newaxis, :]
    object_end_point_info = object_end_point_info[np.newaxis, :]

    code, _ = vq(object_start_point_info, object_start_point_info_codebook)
    object_start_point_info_features[code] += 1

    code, _ = vq(object_end_point_info, object_end_point_info_codebook)
    object_end_point_info_features[code] += 1

    result_feature = merge_2_kmeans_to_1_kmeans(object_start_point_info_features, object_end_point_info_features)
    return result_feature


def cal_trafficlight_object_feature(each_object_info, codebook):
    """
    Calculate the features of a single image given the codebook(vocabulary) generated by clustering method (kmeans), each column is the center of the cluster.
    :param img:
    :param codebook:
    :return:
    """
    object_position_info = each_object_info[0:2]
    object_size_info = each_object_info[2:4]

    object_position_info_codebook = codebook[0]
    object_size_info_codebook = codebook[1]

    position_info_features = np.zeros((object_position_info_codebook.shape[0]))
    size_info_features = np.zeros((object_size_info_codebook.shape[0]))

    object_position_info = object_position_info[np.newaxis, :]
    object_size_info = object_size_info[np.newaxis, :]

    code, _ = vq(object_position_info, object_position_info_codebook)
    position_info_features[code] += 1

    code, _ = vq(object_size_info, object_size_info_codebook)
    size_info_features[code] += 1
    result_feature = merge_2_kmeans_to_1_kmeans(position_info_features, size_info_features)
    return result_feature


def cal_img_features_all(all_object_info, codebook):


    features_all_list = []

    moveable_object_index = 0
    lane_object_index = config.moveable_object_num
    traffic_light_object_index = config.moveable_object_num + config.lane_object_num



    moveable_object_kmeans_cluster_num = codebook[moveable_object_index][0].shape[0] * \
                                         codebook[moveable_object_index][1].shape[0] * \
                                         codebook[moveable_object_index][2].shape[0]
    lane_object_kmeans_cluster_num = codebook[lane_object_index][0].shape[0] * codebook[lane_object_index][1].shape[0]
    traffic_light_kmeans_cluster_num = codebook[traffic_light_object_index][0].shape[0] * \
                                       codebook[traffic_light_object_index][1].shape[0]

    # print(moveable_object_kmeans_cluster_num, lane_object_kmeans_cluster_num, traffic_light_kmeans_cluster_num)
    # exit()
    for i in range(config.moveable_object_num):
        void_numpy = np.zeros(moveable_object_kmeans_cluster_num)
        features_all_list.append(void_numpy)
    for i in range(config.lane_object_num):
        void_numpy = np.zeros(lane_object_kmeans_cluster_num)
        features_all_list.append(void_numpy)
    for i in range(config.traffic_light_object_num):
        void_numpy = np.zeros(traffic_light_kmeans_cluster_num)
        features_all_list.append(void_numpy)

    for three_kinds in range(3):
        for i in all_object_info[three_kinds]:
            if three_kinds == 0:  # moveable object
                i = i[0]
                previous_img_object_info = i[1]
            kmeans_group_serial_num = int(i[0]) - 1
            each_object_info = np.array(i[1:])
            # print(each_object_info)
            # exit()
            if kmeans_group_serial_num <= 4:
                this_object_feature = cal_moveableobject_feature(each_object_info, codebook[kmeans_group_serial_num])

            if 4 < kmeans_group_serial_num <= 8:
                this_object_feature = cal_lane_object_feature(each_object_info, codebook[kmeans_group_serial_num])

            if 8 < kmeans_group_serial_num <= 10:
                this_object_feature = cal_trafficlight_object_feature(each_object_info,
                                                                      codebook[kmeans_group_serial_num])

            features_all_list[kmeans_group_serial_num] = np.sum(
                [features_all_list[kmeans_group_serial_num], this_object_feature], axis=0)

    for i in range(len(features_all_list)):   # 1or0
        for j in range(len(features_all_list[i])):
            if features_all_list[i][j] != 0:
                features_all_list[i][j] = 1

    features_all_list = np.array(features_all_list)

    moveable_object_kmeans_cluster_num = config.moveable_object_num * moveable_object_kmeans_cluster_num
    lane_object_kmeans_cluster_num = config.lane_object_num * lane_object_kmeans_cluster_num
    traffic_light_feature_length = config.traffic_light_object_num * traffic_light_kmeans_cluster_num
    features_all_length = moveable_object_kmeans_cluster_num + lane_object_kmeans_cluster_num + traffic_light_feature_length

    return features_all_list, features_all_length


def get_processed_df(train_data, codebook):
    dataset = []
    single_csv_file_list = []

    for each_img in train_data:
        self_speed_info, all_objects_info, action_label, single_csv_file, three_kinds_of_object_num_in_an_img = each_img
        # print("single_csv_file", single_csv_file)

        features_img, features_all_length = cal_img_features_all(all_objects_info, codebook)

        features_img_one = np.zeros(0)
        for i in features_img:
            features_img_one = np.concatenate((features_img_one, i), axis=0)

        each_img = (features_img_one, action_label, single_csv_file, self_speed_info, all_objects_info)
        dataset.append(each_img)



    return dataset


def K_means_zhang_train_iter():
    batch_size = 50
    # config = x.Config(dataset, embedding)

    np.random.seed(1)
    torch.manual_seed(1)
    torch.cuda.manual_seed_all(1)
    torch.backends.cudnn.deterministic = True

    # use the cross validation method to get the data, pack dataset
    dataset_loader_cross_validation_list, all_data, max_category_num = build_dataset(config.cross_validation_folder_path_pre,
                                                            config.object_settings_path,
                                                            config.action_label_csv_path)

    # one_img_info = (self_speed_info, all_objects_info, action_label, single_csv_file, three_kinds_of_object_num_in_an_img)
    all_object_info = []


    for each_cross_validation in dataset_loader_cross_validation_list:
        for i in each_cross_validation:
            objects_info = i[1]
            all_object_info.append(objects_info)


    kmeans_group = divide_all_object_info_to_each_kind(max_category_num, all_object_info)
    each_kind_object_cluster_num = config.moveable_object_num * config.moveable_object_cluster_num + config.lane_object_num * config.lane_object_cluster_num + config.traffic_light_object_num * config.traffic_light_object_cluster_num
    # print(kmeans_group,len(kmeans_group))
    codebook_list = []
    object_dict = {}
    with open(config.object_settings_path_reverse) as csvfile:
        reader = csv.reader(csvfile)
        for line in reader:
            # intense_loss_line.append(float(line[0]))
            object_dict[line[0]] = line[1]
        next(reader, None)  # jump to the next line

    all_object_codebook = []

    count_flag = 0

    for each_kind_object_numpy in kmeans_group:
        # print(each_kind_object_numpy.shape, count_flag + 1)
        each_object_codebook = []

        if count_flag <= 4:
            codebook_position = cal_codebook(each_kind_object_numpy, config.object_position_cluster_num, config.position_info_range_in_all_info)
            codebook_size = cal_codebook(each_kind_object_numpy, config.object_size_cluster_num, config.size_info_range_in_all_info)
            codebook_motion = cal_codebook(each_kind_object_numpy, config.object_motion_cluster_num, config.motion_info_range_in_all_info)
            each_object_codebook = [codebook_position, codebook_size, codebook_motion]

        if 4 < count_flag <= 8:
            codebook_start_position = cal_codebook(each_kind_object_numpy, config.object_position_cluster_num, config.position_info_range_in_all_info)
            codebook_end_position = cal_codebook(each_kind_object_numpy, config.object_position_cluster_num, config.end_position_info_range_in_all_info)
            each_object_codebook = [codebook_start_position, codebook_end_position]

        if 8 < count_flag <= 10:
            codebook_position = cal_codebook(each_kind_object_numpy, config.object_position_cluster_num, config.position_info_range_in_all_info)
            codebook_size = cal_codebook(each_kind_object_numpy, config.object_size_cluster_num, config.size_info_range_in_all_info)
            each_object_codebook = [codebook_position, codebook_size]
        # print(count_flag, each_object_codebook)
        # exit()
        all_object_codebook.append(each_object_codebook)
        count_flag = count_flag + 1
        # tune_kmeans(count_flag, each_kind_object_numpy)

    cross_validation_iter_list = []

    for each_cross_validation in dataset_loader_cross_validation_list:
        processed_train_data = get_processed_df(each_cross_validation, all_object_codebook)
        each_cross_validation_iter = build_iterator(processed_train_data, batch_size, config.device)
        cross_validation_iter_list.append(each_cross_validation_iter)

    processed_all_data = get_processed_df(all_data, all_object_codebook)
    all_data_iter = build_iterator(processed_all_data, batch_size, config.device)

    return cross_validation_iter_list, all_data_iter, all_object_codebook




